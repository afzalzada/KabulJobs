name: Scrape Job Websites

on:
  schedule:
    # Run every 15 minutes
    - cron: '*/15 * * * *'
  workflow_dispatch: # Allows manual triggering

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3
      with:
        persist-credentials: false
        
    - name: Setup Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '16'
        
    - name: Create package.json
      run: |
        cat > package.json << 'EOL'
        {
          "name": "kabuljobs-scraper",
          "version": "1.0.0",
          "description": "Job aggregator for KabulJobs",
          "main": "scraper.js",
          "scripts": {
            "start": "node scraper.js"
          },
          "dependencies": {
            "axios": "^1.6.0",
            "cheerio": "^1.0.0-rc.12"
          },
          "engines": {
            "node": "16.x"
          }
        }
        EOL
        
    - name: Install dependencies
      run: |
        npm install
        
    - name: Create scraper script
      run: |
        cat > scraper.js << 'EOL'
        // [Paste the updated scraper.js content here]
        EOL
        
    - name: Run scraper
      run: |
        echo "Running scraper..."
        node scraper.js
        
    - name: Commit and push changes
      run: |
        git config user.name "GitHub Actions"
        git config user.email "actions@github.com"
        
        # Check if jobs-data.json exists and has changes
        if [ -f "jobs-data.json" ]; then
          git add jobs-data.json
          git commit -m "Update job data $(date)" || echo "No changes to commit"
          git push
        else
          echo "No jobs-data.json file found, creating one..."
          touch jobs-data.json
          git add jobs-data.json
          git commit -m "Create jobs-data.json $(date)"
          git push
        fi
